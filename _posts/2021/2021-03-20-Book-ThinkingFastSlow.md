---
layout: post
title: Kahneman's Thinking, fast and slow
---

How does our brain work? How do we think what we think? Is everything that we think right? Why do we commit mistakes? What are memories? Why is it so hard to learn something new? Thinking, fast and slow, is the book that gives answers to all these questions. I started reading this book in September 2018, and it took me somewhere around three months to complete this book. Since then, I wanted to write a summary for this one, but there are so many theories and small exercises; a summary wouldn't do justice to what this book holds. 

Kahneman introduces us to two systems within our brain, System 1 and System 2. Our subconscious's work is the interaction of these two systems, which determines our thoughts, affecting decision-making and actions. System 1 is a part of the brain that acts intuitively and instantly, often without conscious control. This system is part of the evolutionary past: man needed to act quickly to survive. System 2 is the part of the brain that we use when we mentally imagine something or think. It handles conscious activity: self-control, choice, deliberate concentration of attention. The relationship between the two systems determines our behavior. And our state, relaxed or tense, depends on which system commands.

<ul>
<li>The mind is often lazy, which affects our mental abilities. Usually, when faced with an unfamiliar situation, System 1 turns to System 2 to sort out the problem. But sometimes, System 1 takes the problem easier than it is and tries to cope with it on its own. The reason for this is our innate mental laziness. Using System 2 requires more energy, and the mind will not do this if it can only use System 1. Kahneman mentions the studies which show that training System 2 requires concentration and self-control. We use a minimum of energy to solve any problem–this is the law of least effort.
</li>
<br>
<li>We are far from always consciously controlling our thoughts and actions.
<blockquote style="color:grey;font-size:17px;">
Example. What will you think about when you see a word with the missing letters "S _ _ P"? Probably about nothing.
But, having heard the word "FOOD," you will add it to "SOUP." This phenomenon is called priming: the idea of ​​"FOOD" gives a setting for "SOUP," and the idea of ​​a "WASH" ​​gives a setting for "SOAP."
</blockquote>
Priming affects not only thoughts, but the body can also be affected.
<blockquote style="color:grey;font-size:17px;">
A study was conducted in which subjects heard words associated with older people. After that, they unconsciously began to move slower.
</blockquote>
Priming shows we do not fully control our actions, judgments, and choices. Certain social and cultural conditions govern us. According to a study by Kathleen Vos, the thought of money gives an orientation to individualism. People who were shown images of money acted more independently and were reluctant to interact with others. One conclusion of the study–living in a money-based society can make our behavior far from altruistic. Priming can affect the choice, decisions, and behavior of an individual, which affects the culture and society in which we live.</li>
<br>
<li>We try to make decisions quickly, lacking enough information
<blockquote style="color:grey;font-size:17px;">
At the party, you meet a man named Ben and find him friendly. Later, when it comes to charity, you recommend Ben as a donor, although the only thing you know about him is his sociability.</blockquote>
We may like one character trait, and we immediately judge the rest. Often an opinion about a person develops, even if we know almost nothing about him. The tendency of the mind to simplify everything leads to erroneous judgments. It is called "exaggerated emotional coherence," known as the halo effect. You surrounded Ben with a halo, although you know very little about him.
<br>
There is a confirmation bias–people's tendency to accept proposals, exaggerations, and previous beliefs.
<blockquote style="color:grey;font-size:17px;">
Answering the question: "Is James friendly?" And having no other information, the subject decides that James is friendly because the mind automatically confirms the proposed idea.
</blockquote>
The halo effect and bias of confirmation arise because the mind is eager to make quick decisions. Relying on false recommendations, excessive simplifications, and filling in data gaps, the mind comes to the wrong conclusions. Like priming, these cognitive phenomena occur unconsciously and affect our choices, judgments, and actions.
</li>
<br>
<li>When making quick decisions, the mind uses heuristics. For a quick assessment of the situation, the mind has created shortcuts to understand your surroundings. They are called heuristics. Often the mind abuses it. Using inappropriate shortcuts to the situation, we make mistakes.
Consider two types of heuristics: <ul>
<li> Replacement heuristics: we simplify the question we are asked.
Example: "This woman claims to be a sheriff. How successful will she be in this position?" We automatically simplify this issue. Instead of analyzing the candidate's experience and principles, we ask ourselves: "Does this woman correspond to our idea of ​​a good sheriff?" If the answer is no, we can refuse this woman, even if she is the best candidate for the position.
</li><br>
<li>Accessibility heuristics: we exaggerate the likelihood of what we often hear or easily remember.
Example: More people die from strokes than in accidents. But 80% of respondents consider accidental death to be more common. The media is much more likely to talk about such deaths, so they are remembered and make a stronger impression.
</li></ul>
<br>
We hardly understand statistics and often make preventable errors in forecasting. To predict specific events, you need to remember the base coefficient. Example: Imagine that in a taxi fleet, there are 20% yellow cars and 80% red cars. The base ratio for a yellow taxi is 20%, and for a red one - 80%. When ordering a taxi, if you want to guess the color of the car and remember the basic coefficients, the forecast will be more accurate. Unfortunately, we often ignore basic information, preferring to focus on expected rather than the most likely events. If five yellow taxis drove past you, the next car will likely be red (remember the base rate). But we expect to see a yellow taxi and are often mistaken.
Ignoring basic information is a common mistake. It is hard for us to remember that everything tends to an average.
</li>
<br>
<li>Our memories are imperfect. We evaluate events retroactively, not based on sensations. The mind has two different "I's" of memory, each of which remembers the situation in its way. Sensing "I" remembers how we felt at the moment of the event. The recollecting "I" remembers how everything happened. The sensing self describes more precisely what happened because our feelings are always accurate. But the recalling "I" dominates in the memory less accurately because it retains memories after the event. There are two reasons for this: <ul>
<li>Ignoring Duration: We ignore the total duration of the event.</li><br>
<li>The peak-end rule: We exaggerate what happens at the end of the event.</li>
</ul>
<blockquote style="color:grey;font-size:17px;">
Example: Before a painful medical procedure, patients were divided into two groups. The procedure in the first group was lengthy, and in the second it was quick, but by the end, the pain intensified. During the procedure, patients were asked about their well-being, and the sensing "I" gave an accurate answer: those who underwent a lengthy procedure felt worse. But later, the recollecting self dominated, and the subjects who underwent the second procedure felt worse.
</blockquote>
</li>
<br>
<li>Correcting mind attention significantly affects thoughts and behavior.
The mind spends a different amount of energy depending on the task. When we do not need to focus, and our energy is low, we are in a state of cognitive ease. But when we need to focus, we use more energy and enter a state of cognitive stress. This energy change influences behavior. In a state of cognitive ease, the intuitive System 1 handles the mind, and the more complex System 2 relaxes. We become creative and happy people, but more often, we make mistakes. In a state of cognitive stress, System 2 dominates, which seeks to recheck our judgments. We will be less creative, but we will avoid many mistakes. You can consciously influence the amount of energy that the mind uses. Try changing the way you provide information. Cognitive tension is useful for solving statistical problems. You can enter this state by reading messages typed in a hard-to-read font. The mind revives and spends more energy trying to comprehend the task. The way information is presented affects risk assessment.
<blockquote style="color:grey;font-size:17px;">
Two groups of psychiatrists were asked: "Is it safe to discharge Mr. Jones from a psychiatric hospital?" The first group was told that "patients such as Mr. Jones may have repeated violent actions in the first months after leaving the hospital with a 10% probability," and the second group was told that "out of a hundred patients like Mr. Jones, ten commit violent acts in the first months after leaving the hospital." Almost twice as many respondents in the second group refused an extract.
</blockquote>
<blockquote style="color:grey;font-size:17px;">
Consider two statements: "a vaccine that prevents the development of a fatal disease in children leads to disability in 0.001% of cases" and "one child out of 100,000 children vaccinated with this vaccine will remain disabled for life." The meaning of the expressions is the same, but the latter evokes in the brain a vivid image of a child crippled by a vaccine, which affects our decision to use the medicine.
</blockquote>
</li>
<br>
<li>While making a choice, we do not base solely on rational thinking. For a long time, a group of economists at the Chicago school, led by renowned scientist Milton Friedman, believed that in our decisions, we are based solely on reasonable arguments – we are guided by the theory of utility, according to which people consider only rational facts. But people are not rational beings – our mind uses processes and uses shortcuts to make quick decisions. Processes such as heuristics and neglect of the denominator show that we constantly act irrationally and even strangely. Rather than base decisions on rational considerations, we often fall under the influence of emotions. An alternative to utility theory is a perspective theory developed by Daniel Kahneman. The theory of perspectives proves that we do not always act rationally.
<blockquote style="color:grey;font-size:17px;">
Example: Consider two situations. 
Situation 1: You have been given $1000. You are now asked to choose one of these options:  50% chance to win $1000 or get $500 for sure.
Situation 2: You have been given $2000. You are now asked to choose one of these options:  50% chance to lose $1000 or lose $500 for sure.

In both cases, you have a choice between the same two options: you can have the certainty of being richer than you are currently by $1500, or accept a gamble in which you have equal chances to be richer by $1000 or $2000.

Result: In the first situation, a large majority of respondents preferred the sure thing. In the second situation, a large majority preferred the gamble.
</blockquote>
Prospect theory explains this behavior. It identifies two reasons based on the fear of losing.
<ul>
<li>
Assessment of reference points.
Example: The initial $1000 or $2000 in both cases affect the willingness to take risks. We value the initial amount both as a starting point and as the actual value.
</li><br>
<li>
The influence of the principle of declining sensitivity: the value that we perceive may differ from the real one.
Example: The perceived value from $1000 to $500 is greater than from $2000 to $1500, although both losses' monetary value is equal.
</li>
</ul>
</li><br>

<li>Images that help us understand the world create prediction errors. To understand the situation and draw a conclusion, the mind instinctively uses cognitive coherence. We make a mental image to explain an idea or concept. 
<blockquote style="color:grey;font-size:17px;">
To understand what to wear in the summer, we recall the image of summer weather – the sun, green foliage, the beach. We trust these images, even when statistical information is at odds with them. If meteorologists predict cool weather in summer, you can still wear shorts and a T-shirt, as the mental image of summer suggests. We are overly confident in our mental images. But you can overcome this self-confidence and learn to predict.
</blockquote>
Use the reference type prediction. Instead of basing decisions on general mental images, a more accurate forecast can be made using specific examples. You can plan a long-term risk minimization policy – particular measures in case of success and failure in the forecast. With their help, you can rely on evidence, not general ideas, and make more accurate predictions.
</li>
