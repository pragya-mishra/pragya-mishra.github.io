---
layout: post
title: Kahneman's Thinking, fast and slow
---

How does our brains work? How do we think what we think? Is everything that we think right? Why do we commit mistakes? What are memories? Why is it so hard to learn something new? Thinking, fast and slow, is the book which gives you answers for all these questions. I started reading this book in September 2018 and it took me somewhere around three months to complete this book. I had been wanting to write a summary for this one since December 2018, but it's so difficult. There are so many theories, small excercises, a summary wouldn't do justice to what this book holds for you. But here I am attempting to finish this summary.

Firstly Kahneman introduces us to two systems with in our brain, System 1 and System 2. The work of our subconscious is the interaction of these two systems, which determines the course of our thoughts, affects decision-making and actions. System 1 is a part of the brain that acts intuitively and instantly, often without our conscious control. This system is part of the evolutionary past: man needed to act quickly in order to survive. System 2 is the part of the brain that we use when we mentally imagine something or think. She is responsible for conscious activity: self-control, choice, deliberate concentration of attention. The relationship between the two systems determines our behavior. And our state, relaxed or tense, depends on which system commands.

<ul>
<li>The Mind is Often Lazy, Which Affects Our Mental Abilities. Usually, faced with an incomprehensible situation, System 1 turns to System 2 to sort out the problem. But sometimes System 1 takes the problem easier than it actually is, and tries to cope with it on its own. The reason for this is our innate mental laziness. We use a minimum of energy to solve any problem – this is the law of least effort. Using System 2 requires more energy, and the mind will not do this if it is certain that it can only use System 1. Kahneman mentions the studies which show that training System 2, that is, concentration and self-control, provides a higher level of intelligence. Lazy and avoiding connecting System 2, the mind limits the power of intelligence.
</li>
<br>
<li>We Are Far From Always Consciously Controlling Our Thoughts and Actions.
<blockquote style="color:grey;font-size:17px;">
Example. What will you think about when you see a word with the missing letters “M _ _ T”? Probably about nothing.
But, having heard the word “FOOD”, you will add it to “MEAT”. This process is called priming: the idea of ​​”FOOD” gives a setting for “MEAT”, and the idea of ​​a “WASH” ​​gives a setting for “SOAP”.
</blockquote>
Priming affects not only thoughts, the body can also be affected.
<blockquote style="color:grey;font-size:17px;">
Example. A study was conducted in which subjects heard words associated with older people. After that, the unconsciously began to move slower.
</blockquote>
Priming shows that we do not fully control our actions, judgments, and choices. We are governed by certain social and cultural conditions. According to a study by Kathleen Vos, the thought of money gives an orientation to individualism. People who were shown images of money acted more independently and were reluctant to interact with others. One of the conclusions of the study – living in a money-based society can make our behavior far from altruism. Priming can affect the choice, decisions, and behavior of an individual, which affects the culture and society in which we live.</li>
<br>
<li>Reason Makes Decisions Quickly, Despite Not Enough Information
<blockquote style="color:grey;font-size:17px;">
Example: At the party, you meet a man named Ben and find him sociable. Later, when it comes to charity, you recommend Ben as a donor, although the only thing you know about him is his sociability.</blockquote>
We may like one character trait, and we immediately judge the rest. Often an opinion about a person develops, even if we know almost nothing about him. The tendency of the mind to simplify everything leads to erroneous judgments. This is called “exaggerated emotional coherence,” known as the halo effect. You surrounded Ben with a halo, although you know very little about him.
</li>
<br>
<li>Reason saves time when making decisions in another way: there is a bias of confirmation – the tendency of people to accept proposals, exaggerations, and their previous beliefs.
<blockquote style="color:grey;font-size:17px;">
Example. Answering the question: “Is James friendly?” And having no other information, the subject decides that James is friendly because the mind automatically confirms the proposed idea.
</blockquote>
The halo effect and bias of confirmation arise because the mind is eager to make quick decisions. Relying on false recommendations, excessive simplifications, and trying to fill in data gaps, the mind comes to the wrong conclusions. Like priming, these cognitive phenomena occur unconsciously and affect our choices, judgments, and actions.
</li>
<br>
<li>When Making Quick Decisions, the Mind Uses Heuristics. For a quick assessment of the situation, the mind has created shortcuts to help you understand your surroundings. They are called heuristics. Often the mind abuses it. Using inappropriate shortcuts to the situation, we make mistakes.
Consider two types of heuristics: <ul>
<li> Replacement heuristics: we simplify the question we are asked.
Example. “This woman claims to be a sheriff. How successful will she be in this position? ” We automatically simplify this issue. Instead of analyzing the candidate’s experience and principles, we ask ourselves: “Does this woman really correspond to our idea of ​​a good sheriff?” If the answer is no, we can refuse this woman, even if she is the best candidate for the position.
</li><br>
<li>The heuristic of accessibility: we tend to exaggerate the likelihood of what we often hear or easily remember.
Example. More people die from strokes than in accidents. But 80% of respondents consider accidental death to be more common. The media are much more likely to talk about such deaths, they are remembered and make a stronger impression.
</li></ul>
</li>
<br>
<li>We Hardly Understand Statistics and Often Make Preventable Errors in Forecasting. To predict certain events, you need to remember the base coefficient. Example. Imagine that in a taxi fleet there are 20% yellow cars and 80% red cars. That is, the base ratio for a yellow taxi is 20%, and for a red one – 80%. If, when ordering a taxi, you want to guess the color of the car, remember the basic coefficients, and the forecast will be more accurate. Unfortunately, we often ignore basic information, preferring to focus on expected rather than the most likely events. If five yellow taxis drove past you, it is very likely that the next car will be red (remember the base rate). But instead, we expect to see a yellow taxi and are often mistaken.
Ignoring basic information is a common mistake. It’s hard for us to remember that everything tends to an average.
</li>
<br>
<li>Our Memories Are Imperfect – We Evaluate Events Retroactively, Not Based On Sensations.The mind has two different “I’s” of memory, each of which remembers the situation in its own way. Sensing “I” remembers how we felt at the moment of the event. The recollecting “I” remembers how everything happened. The sensing self describes more precisely what happened because our feelings are always accurate. But the recalling “I” dominates in the memory less accurate because it retains memories after the event. There are two reasons for this: <ul>
<li>Ignoring Duration: We ignore the total duration of the event.</li><br>
<li>The peak-end rule: We exaggerate what happens at the end of the event.</li>
</ul>
<blockquote style="color:grey;font-size:17px;">
Example. Before a painful medical procedure, patients were divided into two groups. The procedure in the first group was lengthy, and in the second it was quick, but by the end, the pain intensified. During the procedure, patients were asked about their well-being, and the sensing “I” gave an accurate answer: those who underwent a lengthy procedure felt worse. But later, the recollecting self began to dominate, and the subjects who underwent the procedure were quicker but more painful at the end, felt worse.
</blockquote>
</li>
<br>
<li>Correcting Mind Attention Significantly Affects Thoughts and Behavior.
The mind spends a different amount of energy depending on the task. When you do not need to focus and energy is low, we are in a state of cognitive ease. But when we need to focus, we use more energy and enter a state of cognitive stress. These energy changes greatly influence behavior. In a state of cognitive ease, the intuitive System 1 is responsible for the mind, and the more complex System 2 relaxes. We become creative and happy people, but more often we make mistakes. In a state of cognitive stress, System 2 dominates, which seeks to recheck our judgments. We will be less creative, but we will avoid many mistakes.
You can consciously influence the amount of energy that the mind uses. Try changing the way you provide information. When information is repeated or easier to remember, it is more convincing. The mind responds positively to repeated and clear messages. Seeing something familiar, we enter a state of cognitive ease.
</li>
<br>
<li>Cognitive tension is useful for solving statistical problems. You can enter this state by reading messages typed in a hard-to-read font. The mind revives and spends more energy, trying to comprehend the task. The way information is presented affects risk assessment. The evaluation of ideas and problem solving is largely influenced by their formulation. Minor changes in the details or emphasis of a question can change our perception. It seems enough to determine the likelihood of risk, and everyone will relate to this indicator equally. But this is not so. By simply changing the way numerical expression is applied, you can influence your attitude to risk.
<blockquote style="color:grey;font-size:17px;">
Example. Two groups of psychiatrists were asked: “Is it safe to discharge Mr. Jones from a psychiatric hospital?” The first group was told that “patients such as Mr. Jones may have repeated violent actions in the first months after leaving the hospital with a 10% probability,” and the second group was told that “out of a hundred patients like Mr. Jones, ten commit violent acts in the first months after leaving the hospital. ” Almost twice as many respondents in the second group refused an extract.
</blockquote>
Distorts risk assessment and neglect of the denominator – we neglect dry statistics in favor of mental images that influence our decisions. Consider two statements: “a vaccine that prevents the development of a fatal disease in children leads to disability in 0.001% of cases” and “one child out of 100,000 children vaccinated with this vaccine will remain disabled for life.” The meaning of the expressions is the same, but the latter evokes in the brain a vivid image of a child crippled by a vaccine, which affects our decision to use the medicine.
</li>
<br>
<li>Making a Choice, We Are Not Based Solely on Rational Thinking. For a long time, a group of economists at the Chicago school, led by renowned scientist Milton Friedman, believed that in our decisions we are based solely on reasonable arguments – we are guided by the theory of utility, according to which people consider only rational facts. Applying the theory of utility, the Chicago School argued that people in the market are becoming ultra-rational and value products the same way.
<blockquote style="color:grey;font-size:17px;">
Example. Consider two cars: one is equipped with a powerful engine and is safer, and the other is technically faulty and may catch fire when driving. According to utility theory, people should rate the first car higher than the second. Economists believed that the value of all goods and services is determined in such a highly efficient way.
</blockquote>
But people are not rational beings – our mind uses processes and uses shortcuts to make quick decisions. Processes such as heuristics and neglect of the denominator show that we constantly act irrationally and even strangely. Rather Than Base Decisions on Rational Considerations, We Often Fall Under the Influence of Emotions. An alternative to utility theory is perspective theory developed by Daniel Kahneman. The theory of perspectives proves that we do not always act rationally.
<blockquote style="color:grey;font-size:17px;">
Example. Consider two situations. In the first case, you get $ 1,000, and then you are guaranteed to get $ 500, or use a 50% chance to win another $ 1,000. In the second case, you get $ 2,000, after which you are guaranteed to lose $ 500, or use the 50% chance to lose $ 1,000. Purely rational thinking would tell us that both sentences have the same result. But most people in the first case prefer to make the right bet, and in the second post will take a chance.
</blockquote>
Prospect theory may explain this behavior. They identify two reasons based on the fear of losing.<ul>
<li>
Assessment of reference points.
Example. The initial $ 1,000 or $ 2,000 in both cases affect the willingness to take risks. We value the initial amount both as a starting point and as the actual value.
</li><br>
<li>
The influence of the principle of declining sensitivity: the value that we perceive may differ from the real one.
Example. The perceived value from $ 1,000 to $ 500 is greater than from $ 2,000 to $ 1,500, although the monetary value of both losses is equal.
</li>
</ul>
</li><br>

<li>Images That Help Us Understand the World Create Prediction Errors. To understand the situation and draw a conclusion, the mind instinctively uses cognitive coherence. We create a mental image to explain an idea or concept. Example. To understand what to wear in the summer, we recall the image of summer weather – the sun, green foliage, the beach. We trust these images, even when statistical information is at odds with them. Example. If meteorologists predict cool weather in summer, you can still wear shorts and a T-shirt, as the mental image of summer suggests. We are overly confident in our mental images. But you can overcome this self-confidence and learn to predict.

Use the reference type prediction. Instead of basing decisions on general mental images, a more accurate forecast can be made using specific examples. You can plan a long-term risk minimization policy – specific measures in case of success and failure in the forecast. With their help, you can rely on evidence, not general ideas, and make more accurate predictions.

</li>
</ul>

In our minds, two systems work. The first act instinctively and does not require much effort; the second is leisurely and requires concentration. Our thoughts and actions depend on which of the two systems controls our brain.Laziness is inherent in our minds, so the brain uses shortcuts to save energy. This happens unconsciously, and we often make mistakes. Knowing the existence of laziness, we can draw the right conclusions. Repeat the message! Messages are more convincing if we repeat them repeatedly. Recurring events that did not have bad consequences are considered good by definition. Do not let the heuristic of accessibility cloud your view. We often overestimate the likelihood of various disasters due to the vivid images created by the media. In a good mood, creative abilities and intuitive thinking are revealed. A good mood weakens the control of System 2 over the mind. Its vigilant and analytical part transfers control to an intuitive and fast-thinking system, which reveals our creative abilities. This a must book to recognize your brain activity functions you never knew before.
